{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import RFE, SelectFromModel\n",
    "from sklearn.metrics import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "\n",
    "import scipy.stats as stats\n",
    "from scipy import stats\n",
    "from scipy.stats import kruskal\n",
    "from scipy import stats\n",
    "\n",
    "import pycorrcat.pycorrcat as corrcat  #Calcula la V de cramer para variables categóricas.\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import seaborn as sns\n",
    "# os.chdir('C:/Users/santiago/Documents/Proyecto AI Veeduría')\n",
    "os.chdir('C:/Users/juanc/OneDrive/Escritorio/LOCAL_Personal_Veeduria')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descripción breve de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"SECOP_I_MASTER.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimensiones del dataset secop I inicial: \",df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Valor Promedio de la Sancion'].fillna(0,inplace = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orden Entidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "orden = pd.DataFrame(df[\"Orden Entidad\"].value_counts())/len(df)\n",
    "print(\"Porcentaje de entidades por Orden:\")\n",
    "print(orden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,5));\n",
    "pos = [2*i for i in range(1,6)]\n",
    "plt.barh(pos,np.flip(orden[\"Orden Entidad\"])/len(df),\n",
    "         tick_label=np.flip(orden.index));\n",
    "plt.xticks(rotation=45);\n",
    "plt.title(\"Porcentaje de distribucion de entidades por Orden\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de Proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Tipo de proceso:\")\n",
    "df[\"Tipo de Proceso\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estado del proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Estado de proceso:\")\n",
    "df[\"Estado del Proceso\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Causal de Otras Formas de Contratacion Directa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos Causal de Otras Formas de Contratacion Directa:\")\n",
    "df[\"Causal de Otras Formas de Contratacion Directa\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Régimen de Contratación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos Régimen de Contratación:\")\n",
    "df[\"Regimen de Contratacion\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objeto a Contratar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos Objeto a Contratar:\")\n",
    "df[\"Objeto a Contratar\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre grupo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos Nombre Grupo:\")\n",
    "df[\"Nombre Grupo\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre Familia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos Nombre Familia:\")\n",
    "df[\"Nombre Familia\"].value_counts(normalize = True).head(50)#/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre Clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos Nombre Clase:\")\n",
    "df[\"Nombre Clase\"].value_counts(normalize = True).head(10)#/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de Contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Tipo de contrato:\")\n",
    "df[\"Tipo de Contrato\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EsPostConflicto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por EsPostConflicto:\")\n",
    "df[\"EsPostConflicto\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definición del Origen de los Recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Def Origen Recur:\")\n",
    "df[\"Def Origen Recur\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Número Origenes de los recursos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Num Origenes Recur:\")\n",
    "df[\"Num Origenes Recur\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tipo de Identificación del Contratista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Tipo Identifi del Contratista:\")\n",
    "df[\"Tipo Identifi del Contratista\"].value_counts()/len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Departamento y Minicipio del Contratista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por  Dpto y Muni Contratista:\")\n",
    "df[\"Dpto y Muni Contratista\"].value_counts(normalize = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mes Firma del Contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Mes Firma Contrato:\")\n",
    "df[\"Mes Firma Contrato\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Día Mes Firma del Contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Día Mes Firma Contrato:\")\n",
    "df[\"Dia del Mes Firma Contrato\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Día de la Semana Firma del Contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Día de la Firma Contrato:\")\n",
    "df[\"Dia de la Semana Firma Contrato\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plazo en dias de Ejec del Contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Plazo en dias de Ejec del Contrato:\")\n",
    "df[\"Plazo en dias de Ejec del Contrato\"].value_counts(normalize = True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marc Adiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Plazo en dias de Marc Adiciones:\")\n",
    "df[\"Marc Adiciones\"].value_counts(normalize = True).head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicion en Valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Plazo en Adicion en Valor:\")\n",
    "df[\"Adicion en Valor\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adicion en Tiempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Plazo en Adicion en Tiempo:\")\n",
    "df[\"Adicion en Tiempo\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tiempo Adiciones (Dias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Plazo en Tiempo Adiciones (Dias):\")\n",
    "df[\"Tiempo Adiciones (Dias)\"].value_counts(normalize = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nombre Sub Unidad Ejecutora"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Nombre Sub Unidad Ejecutora:\")\n",
    "df[\"Nombre Sub Unidad Ejecutora\"].value_counts(normalize = True).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Moneda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Moneda:\")\n",
    "df[\"Moneda\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Marcación Sanción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Porcentaje de datos por Marc Sancion:\")\n",
    "df[\"Marc Sancion\"].value_counts(normalize = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuantía Proceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cuantia Proceso'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['Cuantia Proceso'] == 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q952 = df['Cuantia Proceso'].quantile(0.95)\n",
    "valor_procesos = df.loc[df['Cuantia Proceso'] < q952, 'Cuantia Proceso']\n",
    "\n",
    "bx = sns.boxplot(y=valor_procesos);\n",
    "bx.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "ax.hist(valor_procesos, bins=50, rwidth=0.8)\n",
    "ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Valor Proceso')\n",
    "plt.title('Distribución de la Cuantía de los Procesos(excluyendo valores superiores al percentil 95)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cuantía Contrato"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Cuantia Contrato'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['Cuantia Contrato'] == 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q952 = df['Cuantia Contrato'].quantile(0.95)\n",
    "valor_contratos = df.loc[df['Cuantia Contrato'] < q952, 'Cuantia Contrato']\n",
    "\n",
    "bx = sns.boxplot(y=valor_contratos);\n",
    "bx.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "ax.hist(valor_contratos, bins=50, rwidth=0.8)\n",
    "ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Valor Proceso')\n",
    "plt.title('Distribución de la Cuantía de los Contratos(excluyendo valores superiores al percentil 95)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valor Total de Adiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Valor Total de Adiciones'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['Valor Total de Adiciones'] == 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_ads['Valor Total de Adiciones'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_ads = df[df['Valor Total de Adiciones'] != 0.0]\n",
    "q952 = valor_ads['Valor Total de Adiciones'].quantile(0.95)\n",
    "ads = valor_ads.loc[valor_ads['Valor Total de Adiciones'] < q952, 'Valor Total de Adiciones']\n",
    "\n",
    "bx = sns.boxplot(y=ads);\n",
    "bx.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "ax.hist(ads, bins=50, rwidth=0.8)\n",
    "ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Valor Proceso')\n",
    "plt.title('Distribución de los valores de adiciones(excluyendo valores superiores al percentil 95)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valor Contrato con Adiciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Valor Contrato con Adiciones'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['Valor Contrato con Adiciones'] == 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q952 = df['Valor Contrato con Adiciones'].quantile(0.95)\n",
    "valor_contrato_ads = df.loc[df['Valor Contrato con Adiciones'] < q952, 'Valor Contrato con Adiciones']\n",
    "\n",
    "bx = sns.boxplot(y=valor_contrato_ads);\n",
    "bx.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "ax.hist(valor_contrato_ads, bins=50, rwidth=0.8)\n",
    "ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Valor Proceso')\n",
    "plt.title('Distribución de la Cuantía de los Contratos(excluyendo valores superiores al percentil 95)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Valor Promedio de la Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Valor Promedio de la Sancion'].isnull().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Valor Promedio de la Sancion'].describe().to_frame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df['Valor Promedio de la Sancion'] == 0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "q952 = df['Valor Promedio de la Sancion'].quantile(0.70)\n",
    "valor_sancion = df.loc[df['Valor Promedio de la Sancion'] < q952, 'Valor Promedio de la Sancion']\n",
    "\n",
    "bx = sns.boxplot(y=valor_sancion);\n",
    "bx.get_yaxis().get_major_formatter().set_scientific(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(14,5))\n",
    "ax.hist(valor_sancion, bins=50, rwidth=0.8)\n",
    "ax.get_xaxis().get_major_formatter().set_scientific(False)\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.xlabel('Valor Proceso')\n",
    "plt.title('Distribución de la Cuantía de los Contratos(excluyendo valores superiores al percentil 95)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pd.cut(valor_sancion, bins=50).value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Primer Filtro de Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dada la primera inspección de las variables  que se consideraron,  se decide eliminar \n",
    "\n",
    "- Orden Entidad\n",
    "- Estado del Proceso\n",
    "- Nombre Familia\n",
    "- Nombre Clase\n",
    "- EsPostConflicto\n",
    "- Nombre Sub Unidad Ejecutora\n",
    "- Moneda\n",
    "- Cuantía Proceso\n",
    "- Valor Contrato con Adiciones\n",
    "\n",
    "Ya sea por la falta de confiabilidad en la información ó la poca distribución que ellas consignan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como varaibles de Identificación tenemos:\n",
    "\n",
    "- UID\n",
    "- Nombre de la Entidad\n",
    "- Código de la Entidad\n",
    "- Descrip Origenes Recur\n",
    "- Id Adjudicación\n",
    "- Identificación del Contratista\n",
    "- Nombre o Razón Social del Contratista\n",
    "- Fecha Firma del Contrato\n",
    "- Fecha Incio Ejecución del Contrato\n",
    "- Fecha Fin de Ejecución del Contrato\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables que se quedan en el modelo\n",
    "\n",
    "- Tipo de Proceso                                  \n",
    "- Causal de Otras Formas de Contratacion Directa   \n",
    "- Regimen de Contratacion                          \n",
    "- Objeto a Contratar                               \n",
    "- Tipo de Contrato                                 \n",
    "- Nombre Grupo                                     \n",
    "- Def Origen Recur                                \n",
    "- Num Origenes Recur                               \n",
    "- Tipo Identifi del Contratista                    \n",
    "- Dpto y Muni Contratista                          \n",
    "- Mes Firma Contrato                               \n",
    "- Dia del Mes Firma Contrato    \n",
    "- Dia de la Semana Firma de Contrato\n",
    "- Plazo en dias de Ejec del Contrato                \n",
    "- Marc Adiciones                                    \n",
    "- Adicion en Valor                                  \n",
    "- Adicion en Tiempo                                \n",
    "- Tiempo Adiciones (Dias)                          \n",
    "- Cuantia Contrato                                \n",
    "- Valor Total de Adiciones                        \n",
    "- Marc Sancion\n",
    "- Valor Promedio de la Sanción\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Definición de las varaibles categóricas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_cat = ['Tipo de Proceso', 'Causal de Otras Formas de Contratacion Directa',\n",
    "       'Regimen de Contratacion', 'Objeto a Contratar', 'Tipo de Contrato', 'Nombre Grupo', 'Def Origen Recur', \n",
    "       'Num Origenes Recur', 'Tipo Identifi del Contratista', 'Dpto y Muni Contratista', 'Mes Firma Contrato',\n",
    "       'Dia del Mes Firma Contrato', 'Dia de la Semana Firma Contrato', 'Marc Adiciones', 'Adicion en Valor', \n",
    "       'Adicion en Tiempo',  'Marc Sancion']\n",
    "\n",
    "#for i in dat_cat:\n",
    " #   df[i] = df[i].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat_cuant = ['Cuantia Contrato', 'Valor Total de Adiciones', 'Valor Promedio de la Sancion',\n",
    "             'Plazo en dias de Ejec del Contrato', 'Tiempo Adiciones (Dias)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_secop = df[['Tipo de Proceso', 'Causal de Otras Formas de Contratacion Directa', 'Regimen de Contratacion', \n",
    "                 'Objeto a Contratar', 'Tipo de Contrato', 'Nombre Grupo', 'Def Origen Recur', 'Num Origenes Recur',\n",
    "                 'Tipo Identifi del Contratista', 'Dpto y Muni Contratista', 'Mes Firma Contrato', 'Dia del Mes Firma Contrato',\n",
    "                 'Dia de la Semana Firma Contrato', 'Marc Adiciones', 'Adicion en Valor', 'Adicion en Tiempo', 'Marc Sancion', \n",
    "                 'Cuantia Contrato', 'Valor Total de Adiciones', 'Valor Promedio de la Sancion',\n",
    "                 'Plazo en dias de Ejec del Contrato', 'Tiempo Adiciones (Dias)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlaciones entre variables independientes Cuantitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "sns.heatmap(base_secop[dat_cuant].corr(), annot=True)\n",
    "#plt.title('Correlación entre variables explicativas numéricas y objetivo', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlaciones entre varaibles independientes categóricas usando V de Cramer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bx = corrcat.corr_matrix(df, dat_cat )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión análisis de correlaciones entre variables independientes categoricas\n",
    "- Hay una correlación perfecta igual a 1 entre 'Def Origen Recur' y 'Num Origenes Recur', **nos quedamos con 'Def Origen Recur'**\n",
    "- Hay una correlacion perfecta igual a 1 entre 'Nombre Grupo' y 'Objeto a Contratar', **nos quedamos con 'Nombre Grupo'**\n",
    "- Hay correlaciones muy cercanas a 1 entre 'Marc Adiciones','Adiciones en Valor' y 'Adiciones en Tiempo' como es de esperarse ya que si hay una Adición en valor o tiempo registrada, se espera que Marc Sancion sea igual a 1, **descartar 'Adiciones en Valor' y 'Adiciones en Tiempo' cuando output es 'Marc Adiciones'**.\n",
    "- Hay correlaciones altas (de 0.73 y 0.66 respectivamente) entre 'Regimen de Contratacion' con 'Tipo de Proceso' y 'Regimen de Contratación' con 'Causal de Otras Formas de Contratación Directa', **se dejan estas variables inicialmente y de ser necesario se dejará solo 1**\n",
    "- Hay correlaciones medias (entre 0.36 y 0.45) entre variables como 'Tipo de Proceso', 'Causal de Otras Formas de Contratación','Objeto a Contratar','Tipo de Contrato' y 'Def Origen Recur'. **Todas esas variables se dejam para los modelos**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(bx, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlación entre variables cuantitativas y cualitativas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_corr = []\n",
    "for x,i in enumerate(dat_cat):\n",
    "    row = []\n",
    "    for y,j in enumerate(dat_cuant):\n",
    "        cc = []\n",
    "        for k in base_secop[i].unique():\n",
    "            cc.append(list(base_secop[base_secop[i] == k][j]))\n",
    "        cc = tuple(cc)\n",
    "        row.append(stats.f_oneway(*cc)[0])\n",
    "    mat_corr.append(row)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he = pd.DataFrame(mat_corr, columns=dat_cuant)\n",
    "he.set_index(pd.Series(dat_cat), inplace = True)\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(he, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlaciones entre Variables independientes y Outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con Coeficiente Pearson (Variables Cuantitativas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(base_secop[dat_cuant+['Marc Adiciones','Adicion en Valor', 'Adicion en Tiempo', 'Marc Sancion']].corr()[['Marc Adiciones','Adicion en Valor', 'Adicion en Tiempo', 'Marc Sancion']], annot=True)\n",
    "#plt.title('Correlación entre variables explicativas numéricas y objetivo', fontsize=16)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion de correlaciones\n",
    "- 'Marc Sancion' y 'Marc Adiciones' no tienen correlación, luego **cuando el output es 'Marc Adiciones' se puede exluir como predictor 'Marc Sancion'** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Con ANOVA (Variables Cuantitativas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vari = ['Marc Adiciones','Adicion en Valor', 'Adicion en Tiempo', 'Marc Sancion']\n",
    "mat_corr2 = []\n",
    "for x,i in enumerate(vari):\n",
    "    row = []\n",
    "    for y,j in enumerate(dat_cuant):\n",
    "        cc = []\n",
    "        for k in base_secop[i].unique():\n",
    "            cc.append(list(base_secop[base_secop[i] == k][j]))\n",
    "        cc = tuple(cc)\n",
    "        row.append(stats.f_oneway(*cc)[0])\n",
    "    mat_corr2.append(row)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "he2 = pd.DataFrame(mat_corr2, columns=dat_cuant)\n",
    "he2.set_index(pd.Series(vari), inplace = True)\n",
    "plt.figure(figsize=(15,7))\n",
    "sns.heatmap(he2, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,10))\n",
    "sns.heatmap(bx[['Marc Adiciones','Adicion en Valor', 'Adicion en Tiempo', 'Marc Sancion']], annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objetos = pd.DataFrame(df[\"Objeto a Contratar\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dic_obj = dict()\n",
    "cods_obj = range(1,len(objetos)+1)\n",
    "for k in cods_obj:\n",
    "    dic_obj[k] = objetos.index[k-1]\n",
    "dic_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(15,7));\n",
    "pos = [3*i for i in range(1,len(objetos)+1)]\n",
    "plt.bar(pos,objetos[\"Objeto a Contratar\"]/len(df),\n",
    "         tick_label=cods_obj);\n",
    "plt.title(\"Porcentaje de distribucion de Objetos a Contratar\");\n",
    "plt.xlabel(\"Codigo de objeto de compra\");\n",
    "plt.ylabel(\"Porcentaje de valores\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación y preprocesamiento de variables\n",
    "- Las variables *Orden Entidad, Tipo de Proceso, Estado de Proceso, Regimen de Contratacion, Objeto a Contratar, Tipo de Contrato* y *Origen de los Recursos* son **variables categóricas** con información textual.\n",
    "\n",
    "- Las variables *Cuantia Contrato, Tiempo Adiciones en Dias, Tiempo Adiciones en Meses, Valor Total de Adiciones, Valor Sancion* son **variables numéricas** de la base de datos.\n",
    "\n",
    "- Las variables *Marc Adiciones* y *Marc Sancion* son **outputs de interés**. Puede que **Marc Adiciones** también sea input y la única variable de salida de los modelos sea *Marc Sancion*.\n",
    "\n",
    "- Se creará una sola columna que indique el tiempo en adiciones en días:\n",
    "    - Si *Rango Ejec del Contrato* en días (D) entonces se usa ese valor\n",
    "    - Si *Rango Ejec del Contrato* en días (M) entonces, asumiendo que cada día sea de 30 meses se calcula $30m + d$ donde $m$ es el tiempo adicionado en meses y $d$ el tiempo adicionado en días"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usar OneHotEncoder\n",
    "cat_cols = [\"Orden Entidad\",\"Tipo de Proceso\",\"Estado del Proceso\",\n",
    "           \"Regimen de Contratacion\",\"Objeto a Contratar\",\"Tipo de Contrato\",\n",
    "           \"Origen de los Recursos\"]\n",
    "print(\"Numero de Nans por columna:\")\n",
    "print([(cat_cols[i], df[cat_cols[i]].isna().sum()) for i in range(len(cat_cols))])\n",
    "#enc = preprocessing.OneHotEncoder(handle_unknown=\"ignore\")\n",
    "#enc.fit(df[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#null_rows = df.index[pd.isnull(df[\"Regimen de Contratacion\"])]\n",
    "#df.iloc[null_rows,:]\n",
    "df[pd.isnull(df[\"Regimen de Contratacion\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se pueden descartar esas filas ya que son muy pocas y no tienen información relevante."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~pd.isnull(df[\"Regimen de Contratacion\"])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos\n",
    "Los  modelos de clasificación que se probarán son:\n",
    "1. K-Nearest Neighbors\n",
    "2. Modelos Bayesianos\n",
    "3. SVM\n",
    "\n",
    "Cada uno de estos modelos se probará utilizando como inputs y outputs las variables de la siguiente manera:\n",
    "1. **Inputs**: categóricas (textuales), Marc Adiciones y variables numéricas, **Output**: Marc Sancion\n",
    "2. **Inputs**: categóricas (textuales), variables numéricas, **Output**: Marc Sancion\n",
    "3. **Inputs**: categóricas (textuales), variables numéricas, **Output**: Marc Adiciones\n",
    "\n",
    "**Nota:** hay que manejar con cuidado el desbalance de las proporciones de los datos, de lo contrario los modelos quedan sesgados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Análisis de correlaciones entre Inputs y Output\n",
    "## Ayudas\n",
    "- Test chi cuadrado\n",
    "- Cramers'V\n",
    "- Bonferroni Correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columnas con texto categoricas\n",
    "# ['Orden Entidad','Tipo de Proceso','Estado del Proceso','Regimen de Contratacion','Objeto a Contratar','Tipo de Contrato','Origen de los Recursos']\n",
    "#Transformación de texto a codigos con OneHotencoder\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(df[cat_cols])\n",
    "# enc.categories: arreglo con nombre de categorias porcolumna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de diccionarios de codigos para cada columna categorica\n",
    "dic_cods = dict()\n",
    "for i in range(len(enc.categories_)):\n",
    "    d = dict()\n",
    "    for j in range(len(enc.categories_[i])):\n",
    "        d[enc.categories_[i][j]] = j\n",
    "    dic_cods[cat_cols[i]] = d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reemplazando texto por codigos\n",
    "df_cod = deepcopy(df)\n",
    "for name in cat_cols:\n",
    "    df_cod = df_cod.replace({name:dic_cods[name]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_cod es el mismo dataset pero con las variables categoricas codificadas\n",
    "df_cod.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remuestreo para balancear clases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_0 = df[df[\"Marc Sancion\"]==0].sample(n=5000,replace=True,random_state=0)\n",
    "df_1 = df[df[\"Marc Sancion\"]==1].sample(n=5000,replace=True,random_state=0)\n",
    "\n",
    "df_sample = pd.concat([df_0,df_1],axis=0)\n",
    "\n",
    "df_sample = df_sample.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Inputs textuales + Marc_sancion, output: Marc Sancion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Análisis de correlación inputs categóricos y output Marc Sancion categorico\n",
    "La correlación entre dos variables categóricas se puede medir con las siguientes técnicas: **test chi cuadrado, Cramers's V**.\\\n",
    "Primero analicemos analicemos con el test de Chi cuadrado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chi2_test(var1,var2,prob=0.95):\n",
    "    \"\"\"\n",
    "    Determina si 2 variables categoricas tienen algún tipo de correlacion con test de chi cuadrado\n",
    "    args:\n",
    "        var1: variable 1\n",
    "        var2: variable 2\n",
    "        prob: nivel de confianza para test, por defecto 95%\n",
    "    returns:\n",
    "        metricas de test\n",
    "    \"\"\"\n",
    "    table = pd.crosstab(var1,var2)\n",
    "    # Estadistico cho2, p-valor, grados de libertad estimados y frecuencias estimadas\n",
    "    # basado en sumas marginales de la tabla\n",
    "    stat,p,dof,expected = chi2_contingency(table)\n",
    "    print(\"Degrees of freedom (Dof): \", dof)\n",
    "    #print(expected)\n",
    "    #prob = 0.95\n",
    "    # Percent point function, inverse distribution function\n",
    "    # Calcula probabilidad que la variable sea menor o igual que x dado un x\n",
    "    # interpret statistic\n",
    "    critical=chi2.ppf(prob,dof)\n",
    "    print(\"Probability = %.3f, critical = %.3f, stat = %.3f\" % (prob,critical,stat))\n",
    "    if abs(stat) >=critical:\n",
    "        print(\"Dependent (reject H0)\")\n",
    "    else:\n",
    "        print(\"Independent (fail to reject H0)\")\n",
    "    # interpet p-value\n",
    "    alpha = 1.0-prob\n",
    "    print(\"Significance = %.3f, p-value = %.3f\" % (alpha,p))\n",
    "    if p <=alpha:\n",
    "        print(\"Dependent (reject H0)\")\n",
    "    else:\n",
    "        print(\"Independent (fail to reject H0)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entre Orden Entidad y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Orden Entidad\"\n",
    "col2 = \"Marc Sancion\"\n",
    "sns.heatmap(pd.crosstab(df_sample[col1],df_sample[col2],normalize=True),annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(df[\"Orden Entidad\"],df[\"Marc Sancion\"])\n",
    "table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_sample[\"Orden Entidad\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entre tipo de Proceso y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Tipo de Proceso\"\n",
    "col2 = \"Marc Sancion\"\n",
    "sns.heatmap(pd.crosstab(df_sample[col1],df_sample[col2],normalize=True),annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table = pd.crosstab(df_sample[\"Tipo de Proceso\"],df_sample[\"Marc Sancion\"])\n",
    "chi2_test(df_sample[\"Tipo de Proceso\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Estado del Proceso y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Estado del Proceso\"\n",
    "col2 = \"Marc Sancion\"\n",
    "sns.heatmap(pd.crosstab(df_sample[col1],df_sample[col2],normalize=True),annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_sample[\"Estado del Proceso\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Regimen de Contratacion y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Regimen de Contratacion\"\n",
    "col2 = \"Marc Sancion\"\n",
    "sns.heatmap(pd.crosstab(df_sample[col1],df_sample[col2],normalize=True),annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_sample[\"Regimen de Contratacion\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Objeto a Contratar y Marc Sancion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_sample[\"Objeto a Contratar\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Objeto a Contratar\"\n",
    "col2 = \"Marc Sancion\"\n",
    "tab_norm = pd.crosstab(df_sample[col1],df_sample[col2],normalize=True)\n",
    "fig = plt.figure(figsize=(20,13))\n",
    "sns.heatmap(tab_norm.iloc[:int(len(tab_norm)/2.0),:],annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2 + \" (parte 1)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,13))\n",
    "sns.heatmap(tab_norm.iloc[int(len(tab_norm)/2.0):,:],annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2 + \" (parte 2)\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_sample[\"Objeto a Contratar\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Tipo de Contrato y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Tipo de Contrato\"\n",
    "col2 = \"Marc Sancion\"\n",
    "sns.heatmap(pd.crosstab(df_sample[col1],df_sample[col2],normalize=True),annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_sample[\"Tipo de Contrato\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Origen de los Recursos y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col1 = \"Origen de los Recursos\"\n",
    "col2 = \"Marc Sancion\"\n",
    "sns.heatmap(pd.crosstab(df_sample[col1],df_sample[col2],normalize=True),annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_sample[\"Origen de los Recursos\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Marc Adicion y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "col1 = \"Marc Adiciones\"\n",
    "col2 = \"Marc Sancion\"\n",
    "sns.heatmap(pd.crosstab(df_sample[col1],df_sample[col2],normalize=True),annot=True);\n",
    "plt.title(\"Crosstab normalizado entre \"+col1+ \" y \"+col2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chi2_test(df_sample[\"Marc Adiciones\"],df_sample[\"Marc Sancion\"],prob=0.95)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Variables numéricas y Marc Sancion\n",
    "Las variables numéricas son *Cuantia Contrato, Valor Total de Adiciones* y una nueva variable llamada *Adiciones en Dias*. Esta última representa el timepo adicionado en días, construida a partir de *Rango de Ejec del Contrato* asumiendo que si *Rango de Ejec del Contrato* es M entonces la cada se suma *Tiempo Adiciones en Meses* $\\times$ 30 a *Tiempo Adiciones en Dias*.\n",
    "\n",
    "La correlación entre variables numéricas y una variable categórica se puede calcular con la **correlación de punto biserial**.\n",
    "Las hipótesis para esta correlación son iguales a cualquier test de correlación:\n",
    "- **La hipótesis nula $H_0$ es que  no hay una correlación significativa entre las variables**. \n",
    "- Si el p-valor es menor que el nivel de significancia $\\alpha$ (en general de 0.05) se rechaza la hipótesis nula. Más info [aquí](https://towardsdatascience.com/eveything-you-need-to-know-about-interpreting-correlations-2c485841c0b8#:~:text=A%20p%2Dvalue%20is%20the,sample%20occurred%20due%20to%20chance.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Cuantia Contrato y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stats.pointbiserialr(a, b): retorna el coeficiente de correlación y el p-valor\n",
    "# a: variable binaria, b: variable continua\n",
    "stats.pointbiserialr(df_sample[\"Marc Sancion\"], df_sample[\"Cuantia Contrato\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y0 = df_0[\"Cuantia Contrato\"].mean()\n",
    "y1 = df_1[\"Cuantia Contrato\"].mean()\n",
    "plt.scatter(df_sample[\"Marc Sancion\"], df_sample[\"Cuantia Contrato\"]);\n",
    "plt.plot([0,1],[y0,y1],'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Valor total de las adiciones y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pointbiserialr(df_sample[\"Marc Sancion\"], df_sample[\"Valor Total de Adiciones\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y0 = df_0[\"Valor Total de Adiciones\"].mean()\n",
    "y1 = df_1[\"Valor Total de Adiciones\"].mean()\n",
    "plt.scatter(df_sample[\"Marc Sancion\"], df_sample[\"Valor Total de Adiciones\"]);\n",
    "plt.plot([0,1],[y0,y1],'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Entre Adiciones en dias y Marc Sancion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dias = np.zeros(len(df_sample))\n",
    "for i in range(len(df_sample)):\n",
    "    if df_sample[\"Rango de Ejec del Contrato\"][i] == \"M\":\n",
    "        dias[i] = 30*df_sample[\"Tiempo Adiciones en Meses\"][i] + df_sample[\"Tiempo Adiciones en Dias\"][i]\n",
    "    else:\n",
    "        dias[i] = df_sample[\"Tiempo Adiciones en Dias\"][i]\n",
    "df_sample[\"Adiciones en Dias\"] = dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.pointbiserialr(df_sample[\"Marc Sancion\"], df_sample[\"Adiciones en Dias\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusiones para variables categóricas:\n",
    "- Por ahora, se descarta *Orden Entidad*\n",
    "- Validar listados de entidades de orden Nacional Centralizado,..., con valores pequeños según crosstab\n",
    "- Considerar modelos  **sin** Prestación de servicios\n",
    "- Descartar *Estado del Proceso*\n",
    "- Calcular probabilidades condicioneales con tabla de *Marc Adiciones* y *Marc Sancion*\n",
    "- Calcular porcentajes de Adición con respecto a *Cuantia Contrato*, el output es *Marc Sancion*.\n",
    "- **Modelos a probar: regresión logística, árbol de desición**\n",
    "- Considerar tiempos de aducuibes cuando output es *Marc Sancion*\n",
    "- Utilizar **Random Forest** para selección de predictores\n",
    "\n",
    "**Nota:** hacer corrstabs como graficas de barras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión logística\n",
    "Primero creamos variables categóricas con dummies (1 y 0)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cat_vars = ['Orden Entidad','Tipo de Proceso','Estado del Proceso','Regimen de Contratacion','Objeto a Contratar','Tipo de Contrato','Origen de los Recursos', \"Marc Adiciones\"]\n",
    "cat_vars = ['Orden Entidad','Tipo de Proceso','Estado del Proceso','Regimen de Contratacion',\n",
    "            'Objeto a Contratar','Tipo de Contrato','Origen de los Recursos']\n",
    "df_cat = pd.DataFrame()\n",
    "for var in cat_vars:\n",
    "    df_dum = pd.get_dummies(df[var])\n",
    "    # Diccionario para cambiar nombres\n",
    "    dic_new_names = dict()\n",
    "    for cat in df_dum.columns:\n",
    "        dic_new_names[cat] = str(var)+\"_\"+str(cat)\n",
    "    # Aclarando nombre de variables categoricas\n",
    "    df_dum = df_dum.rename(columns=dic_new_names)\n",
    "    # Se pega el dataframe de dummies\n",
    "    df_cat = pd.concat([df_cat,df_dum],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora *df_cat* es un data frame con las variables categóricas por dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creacion de variable Adiciones en Dias para el dataframe principal\n",
    "dias = np.zeros(len(df))\n",
    "for i in range(len(df)):\n",
    "    # Casos en los que se detiene\n",
    "    if i in {123225,410080,472437,492844}:\n",
    "        dias[i] = 0\n",
    "    elif df[\"Rango de Ejec del Contrato\"][i] == \"M\":\n",
    "        dias[i] = 30*df[\"Tiempo Adiciones en Meses\"][i] + df[\"Tiempo Adiciones en Dias\"][i]\n",
    "    elif df[\"Rango de Ejec del Contrato\"][i] == \"D\":\n",
    "        dias[i] = df[\"Tiempo Adiciones en Dias\"][i]\n",
    "df[\"Adiciones en Dias\"] = dias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pegamos las variables numéricas con df_cat\n",
    "df_cat = pd.concat([df_cat,df[[\"Cuantia Contrato\", \"Valor Total de Adiciones\",\n",
    "                               \"Adiciones en Dias\",\"Marc Sancion\", \"Marc Adiciones\"]]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_cat[\"Marc Sancion\"].value_counts())\n",
    "print(df_cat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceo de clases se puede hacer con SMOTE en python\n",
    "# Por ahora, se elige  muestrea 5000 datos de la clase 0 y remuestrea 5000 de la clase 1\n",
    "df_cat_0 = df_cat[df_cat[\"Marc Sancion\"]==0].sample(n=5000,replace=True,random_state=0)\n",
    "df_cat_1 = df_cat[df_cat[\"Marc Sancion\"]==1].sample(n=5000,replace=True,random_state=0)\n",
    "\n",
    "df_cat_sample = pd.concat([df_cat_0,df_cat_1],axis=0)\n",
    "\n",
    "df_cat_sample = df_cat_sample.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables con Recursive Feature Extraction (RFE)\n",
    "Esta técnica selecciona variables considerando conjuntos cada vez más pequeños de variables, inicialmente se entrena con el conjunto de datos inicial. A medida que itera, descarta las variables menos importantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_cat_sample.loc[:,[n for n in df_cat_sample.columns  if n!= \"Marc Sancion\"]]\n",
    "y = df_cat_sample[\"Marc Sancion\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "rfe = RFE(logreg,n_features_to_select = 30)\n",
    "rfe = rfe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#list(df_cat_sample.columns[rfe.support_.reshape(30)])\n",
    "best_cols_idx = np.where(rfe.support_ == True)\n",
    "best_cols = df_cat_sample.columns[best_cols_idx]\n",
    "best_cols = [c for c in best_cols if c != \"Marc Sancion\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Con las variables seleccionadas\n",
    "X = df_cat_sample[best_cols]\n",
    "y = df_cat_sample[\"Marc Sancion\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "logit_model=sm.Logit(y,X)\n",
    "result=logit_model.fit(method='bfgs',maxiter=200)\n",
    "print(result.summary2())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.value_counts())\n",
    "print(\"-------------\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotCM(ytrue, ypred, titulo, clases=None, normalize = False, ax = None):\n",
    "    \"\"\" Funcion para calcular y visualizar la matriz de confusion\"\"\"\n",
    "    \n",
    "    if clases == None:\n",
    "        clases = list(set(ytrue))\n",
    "        clases.sort() # etiquetas unicas ordenadas alfabeticamente\n",
    "    \n",
    "    CM = confusion_matrix(ytrue,ypred, labels=clases)\n",
    "    \n",
    "    #Normaliza la matriz de confusion dividiendo cada fila por el total de verdaderos\n",
    "    if normalize:\n",
    "        CM = 100*CM / CM.sum(axis=1).reshape(-1,1) #Aprovechando el Broadcasting!\n",
    " \n",
    "    df = pd.DataFrame(CM, index=clases, columns=clases)\n",
    "    df.index.name = 'True'; df.columns.name = 'Predicted'\n",
    "    \n",
    "    sns.heatmap( df, # Visualizando la matriz de confusion\n",
    "             annot=True, fmt='2.1f', cmap='ocean_r',cbar=False,square=True, annot_kws={'fontsize':16}, ax=ax )\n",
    "    plt.title(titulo)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plotCM(y_test,y_pred,\"Matriz de confusion (1: con sancion, 0:sin sancion)\",\n",
    "      normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica ROC AUC\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada:\n",
    "logreg = LogisticRegression()\n",
    "cv_scores = cross_val_score(logreg,X_train,y_train,cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selección de variables con conclusiones iniciales y quitando Contrato por prestacion de servicios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df_cat.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sin Orden Entidad, sin Tipo de Contrato_ Prestación de Servicios\n",
    "cols = [n for n in df_cat.columns if \"Orden Entidad\" not in n]\n",
    "df2 = df_cat[cols]\n",
    "df2 = df2[df2['Tipo de Contrato_Prestación de Servicios'] == 0]\n",
    "print(df2.shape)\n",
    "print(df2[\"Marc Sancion\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balanceando clases\n",
    "df2_0 = df2[df2[\"Marc Sancion\"]==0].sample(n=5000,replace=True,random_state=0)\n",
    "df2_1 = df[df_cat[\"Marc Sancion\"]==1].sample(n=5000,replace=True,random_state=0)\n",
    "\n",
    "df2_sample = pd.concat([df2_0,df2_1],axis=0)\n",
    "\n",
    "df2_sample = df_cat_sample.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df2_sample.loc[:,[n for n in df2_sample.columns if n != \"Marc Sancion\"]]\n",
    "y = df2_sample[\"Marc Sancion\"]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotCM(y_test,y_pred,\"Matriz de confusion sin Cont. Prestacion de servicios \\n (1: con sancion, 0:sin sancion)\",\n",
    "      normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grafica ROC AUC\n",
    "logit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validación cruzada:\n",
    "logreg = LogisticRegression()\n",
    "cv_scores = cross_val_score(logreg,X_train,y_train,cv=5)\n",
    "cv_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos para detectar contratos con adiciones - SECOP I\n",
    "En este notebook se realiza la prueba de posibles modelos predictivos con los cuales se pretende detectar anomalías en la contratación pública de Bogotá. Se usa como insumo la base de datos SECOP_I_MASTER2.\n",
    "\n",
    "Base con la cual se proceden a realizar modelos de clasificación binarios para 3 diferentes variables objetivo que determinan si el contrato tuvo alguna adición del respectivo tipo o no; `Marc Adiciones`,`Adiciones en Valor` y `Adiciones en Valor`. Adicionalmente, se realizan modelos con y sin incluir los modelos con prestacion de servicios.\n",
    "\n",
    "**Implementación de modelos después de análisis exploratorio y de selección de variables**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Buscar útilidad de AIC Y BIC para modelos de clasificación y su calculo.https://stackoverflow.com/questions/48185090/how-to-get-the-log-likelihood-for-a-logistic-regression-model-in-sklearn\n",
    "- Probar elección de hiperparámetros con métrica fbeta.\n",
    "- Balancear hacia arriba los datos para modelos de contratos diferentes a prestación de servicio debido al bajo número de observaciones.\n",
    "- Paper Jorge y Juan David revisar consistencia.\n",
    "- Visualizar arbol de decisión sencillo.\n",
    "- Segunda versión del reporte 2, incluye sección de EDA y modelos implementados en sección 4. También solucionar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Funciones auxiliares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gráficas\n",
    "def corr_Matrix(data):\n",
    "    '''\n",
    "    Gráfica la matríz de correlación entre todas las variables \n",
    "    de la base de datos usada.\n",
    "    '''\n",
    "    f,ax = plt.subplots(figsize = (15,14))\n",
    "    sns.heatmap(data.corr(),cmap = 'ocean_r', annot = True, cbar = False )\n",
    "    ax.set_title('Correlation matrix')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def plot_ROC(model, X_test, y_test, scaler, model_name='Model'):\n",
    "    '''\n",
    "    Gráfica la curva ROC y calcula el AUC para un modelo entrenado dados unos datos de prueba.\n",
    "    Entradas:\n",
    "            model: modelo sklearn entrenado del que se usa el método predict_proba()\n",
    "            X_test: variables independientes de prueba.\n",
    "            Y_test: variable dependiente de prueba.\n",
    "            scaler: objeto preprocessing.StandardScaler() entrenado junto al modelo para escalar X_test.\n",
    "            model_name: string con el nombre del modelo que se pasa para usar como leyenda de la curva ROC\n",
    "    Salida:\n",
    "            Gráfica curva ROC e impresión del AUC.\n",
    "    '''\n",
    "    ns_probs = [0 for _ in range(len(y_test))]\n",
    "    lr_probs = model.predict_proba(scaler.transform(X_test))\n",
    "    lr_probs = lr_probs[:, 1]\n",
    "    \n",
    "    lr_auc = roc_auc_score(y_test, lr_probs)\n",
    "    print(\"Model: ROC AUC = {:1.3f}\".format(lr_auc))\n",
    "\n",
    "    ns_fpr, ns_tpr, _ = roc_curve(y_test, ns_probs)\n",
    "    lr_fpr, lr_tpr, _ = roc_curve(y_test, lr_probs)\n",
    "\n",
    "    plt.plot(ns_fpr, ns_tpr, linestyle = '--') \n",
    "    plt.plot(lr_fpr, lr_tpr, marker = '.', label = model_name)\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.title('ROC curve')\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "def plot_CM(y_true, y_pred,norm=None):\n",
    "    '''\n",
    "    Tabla de matríz de confusión\n",
    "    '''\n",
    "    cm = confusion_matrix(y_true, y_pred,normalize=norm)\n",
    "    cm_df = pd.DataFrame(cm, index = ['No','Sí'], columns = ['No','Sí'])\n",
    "    cm_df.index.name = 'True'; cm_df.columns.name = 'Predicted'\n",
    "    return cm_df\n",
    "\n",
    "def balance(base, target):\n",
    "    '''\n",
    "    Función para balancear las bases de datos hacia el valor de la variables objetivo con menos observaciones.\n",
    "    Entradas:\n",
    "            base: base de pandas a balancear.\n",
    "            target: nombre de la variable objetivo respecto a la que se balanceará.\n",
    "    Salida:\n",
    "            df_downsample: base balanceada.\n",
    "    '''\n",
    "    df_majority = base[base[target] == 0]\n",
    "    df_minority = base[base[target] == 1]\n",
    "    \n",
    "    n = min(base[target].value_counts())\n",
    "    df_majority_downsampled = resample(df_majority, replace = False, n_samples = n, random_state = 123)\n",
    "    df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "    \n",
    "    return df_downsampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funciones para ejecutar modelos\n",
    "def feature_selection(X, y,max_vars):\n",
    "    '''\n",
    "    Selección de variables estadísticamente significativas mediante random forest\n",
    "    Entradas: X, y: Variables independietes y dependientes como base y serie de pandas respectivamente.\n",
    "    Salida: X_varSelec: Pandas dataframe solo con las variables significativas.\n",
    "    '''\n",
    "    sel = SelectFromModel(RandomForestClassifier(n_estimators = 100),max_features = max_vars)\n",
    "    sel.fit(X, y)\n",
    "    \n",
    "    variables_significativas = np.where(sel.get_support() == True)\n",
    "    nombres_columnas = []\n",
    "    for idx, i in enumerate(variables_significativas):\n",
    "        nombres_columnas.append(X.columns[i])\n",
    "    nombres_columnas = list(nombres_columnas[0])\n",
    "    print(\"Variables estadísticamente significativas: \\n{}\".format(nombres_columnas))\n",
    "    \n",
    "    X_varSelec = sel.transform(X)\n",
    "    X_varSelec = pd.DataFrame(X_varSelec, columns = nombres_columnas)\n",
    "    \n",
    "    return X_varSelec\n",
    "\n",
    "\n",
    "def reg_log(X, y):\n",
    "    '''\n",
    "    Modelo de regresión logítica.\n",
    "    Función para la realización de modelos mediante regresión logística. Imprime accuracy de la validación cruzada\n",
    "    y datos de prueba , así como el recall en los datos de prueba.\n",
    "    Entradas: \n",
    "            X: base de pandas con variables independientes.\n",
    "            Y: serie de pandas con la variable objetivo.\n",
    "    Salidas:\n",
    "            rl: modelo de regresión logística entrenado.\n",
    "            X_test, y_test: Datos de prueba.\n",
    "            y_pred: valores de la variable respuesta estimados.\n",
    "            scaler: objeto para escalar valores entrenado.\n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    \n",
    "    rl = LogisticRegression(max_iter = 500)\n",
    "    vc = cross_val_score(rl, scaler.transform(X_train), y_train, cv = 10, scoring = \"accuracy\")\n",
    "    accuracy = vc.mean()\n",
    "    print(\"Accuracy para Regresión Logística con validación cruzada: {:1.4f} \".format(accuracy) )\n",
    "    \n",
    "    rl = LogisticRegression(max_iter = 500)\n",
    "    rl.fit(scaler.transform(X_train), y_train)\n",
    "\n",
    "    y_pred = rl.predict(scaler.transform(X_test))\n",
    "    print(\"El accuracy del test es: {:1.4f}\".format( accuracy_score(y_test, y_pred) ))\n",
    "    print(\"La sensitividad(recall) del test es: {:1.4f}\".format( recall_score(y_test, y_pred) ))\n",
    "    \n",
    "    return rl, X_test, y_test, y_pred, scaler\n",
    "\n",
    "\n",
    "def random_forest(X, y):\n",
    "    '''\n",
    "    Modelo random forest para clasificación.\n",
    "    Entradas: \n",
    "            X: base de pandas con variables independientes.\n",
    "            Y: serie de pandas con la variable objetivo.\n",
    "    Salidas:\n",
    "            arb: modelo de random forest entrenado.\n",
    "            X_test, y_test: Datos de prueba.\n",
    "            y_pred: valores de la variable respuesta estimados.\n",
    "            scaler: objeto para escalar valores entrenado.    \n",
    "    '''\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42, stratify = y)\n",
    "    scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "    \n",
    "    arb = RandomForestClassifier(random_state=42)\n",
    "    arb.fit(scaler.transform(X_train), y_train)\n",
    "    \n",
    "    y_pred_arb = arb.predict(scaler.transform(X_test))\n",
    "    print(\"Accuracy del test: {:1.4f}\".format( accuracy_score(y_test, y_pred_arb) ))\n",
    "    print(\"La sensitividad(recall) del test es: {:1.4f}\".format( recall_score(y_test, y_pred_arb) ))\n",
    "\n",
    "    return arb, X_test, y_test, y_pred_arb, scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tarda un poco en leer los datos\n",
    "df = pd.read_csv(\"SECOP_I_MASTER2.csv\")\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_ad = [n for n in df.columns if \"Adicion\" in n or \"adicion\" in n]\n",
    "cols_ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"Dimension de los datos: \",df.shape)\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identificación de Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Variables a excluir al momento de entrenar modelos\n",
    "vars_a_excluir = [\"Orden Entidad\",\"Estado del Proceso\", \"Nombre Familia\",\n",
    "                  \"Nombre Clase\",\"Nombre Sub Unidad Ejecutora\",\"Moneda\",\"Cuantia Proceso\",\n",
    "                  \"Valor Contrato con Adiciones\",\"Objeto a Contratar\",\"Num Origenes Recur\",\n",
    "                 ]\n",
    "# Variables que no son utiles para modelos\n",
    "vars_a_excluir += [\"UID\",\"Nombre de la Entidad\",\"Código de la Entidad\",\"Descrip Origenes Recur\",\n",
    "                      \"ID Ajudicacion\",\"Tipo Identifi del Contratista\",\"Identificacion del Contratista\",\n",
    "                     \"Nom Raz Social Contratista\",\"Fecha de Cargue en el SECOP\",\"Fecha de Firma del Contrato\",\n",
    "                     \"Fecha Ini Ejec Contrato\",\"Fecha Ini Ejec Contrato\",\"Fecha Fin Ejec Contrato\"\n",
    "                     ,'Ultima Actualizacion']\n",
    "# vars_cinluidas contiene los target\n",
    "vars_incluidas = [name for name in df.columns if name not in vars_a_excluir]\n",
    "# Marc Sancion como input es exluido\n",
    "vars_categoricas = [\"Tipo de Proceso\",\"Causal de Otras Formas de Contratacion Directa\",\"Regimen de Contratacion\",\n",
    "                    \"Tipo de Contrato\",\"Nombre Grupo\",\"EsPostConflicto\",\"Def Origen Recur\",\n",
    "                    \"mismo detalle objeto a contratar despues de firma\",\"Dpto y Muni Contratista\",\"Mes Firma Contrato\",\n",
    "                   \"Dia del Mes Firma Contrato\",\"Dia de la Semana Firma Contrato\",\"Marc Adiciones\",]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dudas\n",
    "- Las variables en formato fecha fueron incluidas como inputs en el modelo?\n",
    "-  EsPostConflicto el desbalance es enorme, dejarla?\n",
    "-  Diccionario de variables que quedaron en SECOP_1_MASTER2\n",
    "- Departamento de Contratista hay unos pocos que vienen de municipios externos a Bogotá y Cundinamarca, dejarlos?\n",
    "- Tiempo Adiciones (Dias) tiene datos negativos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Para Marc Adiciones:\")\n",
    "print(df[\"Marc Adiciones\"].value_counts(),\"\\n \\n\")\n",
    "print(\"Para Adicion en Valor:\")\n",
    "print(df[\"Adicion en Valor\"].value_counts(),\"\\n \\n\")\n",
    "print(\"Para Adicion en Tiempo:\")\n",
    "print(df[\"Adicion en Tiempo\"].value_counts(),\"\\n \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aunque el desbalance no es tan drástico como con `Marc Sancion` sí se mantiene un desbalance de 3 a 1 aproximadamente siendo la categroría 1 la menos presente para los 3 outputs. Por lo tanto, para cada output de adición se hará un downsampling de la clase 0 mientras que se mantiene intacta la cantidad de datos de la clase 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos con output `Marc Adiciones`\n",
    "- Se exluye la informacion acerca de adiciones excepto el target 'Marc Adiciones'.\n",
    "- Se **excluye la información acerca de sanciones, es decir 'Marc Sancion y Valor Sancion'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# _MA: para Marc Adiciones\n",
    "df_downsampled_MA = balance(df,\"Marc Adiciones\")\n",
    "y_down_MA = df_downsampled_MA[\"Marc Adiciones\"]\n",
    "# Eliminamos las columnas innecesarias incluyendo la del target\n",
    "X_down_MA = df_downsampled_MA.drop(columns = vars_a_excluir + [\"Marc Adiciones\",\"Adicion en Valor\",\"Adicion en Tiempo\",\n",
    "                                                               \"Marc Sancion\",\"Valor Total de Adiciones\"])\n",
    "# Pasamos a dummies las columnas que sean categoricas\n",
    "X_down_MA = pd.get_dummies(data = X_down_MA, columns=list(set(vars_categoricas) - {\"Marc Adiciones\",\"Marc Sancion\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# No esta quitando Valor Sancion :(\n",
    "# Variables dummies\n",
    "list(X_down_MA.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion de las variables mas importantes con Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dimension de dataset con dumies: \",X_down_MA.shape)\n",
    "print(\"Cantidad de variables en dataset con dummies: \",X_down_MA.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nota: La primera seleccion de variables tarda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vars = 30\n",
    "X_fselec = feature_selection(X_down_MA, y_down_MA, max_vars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entre las variables seleccionadas, las variables más correlacionadas son `cantidad de palabras objeto a contratar` y `cantidad de palabras objeto del contrato a la firma`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,8))\n",
    "sns.heatmap(X_fselec.corr(),annot=True);\n",
    "#plt.xticks(np.arange(8),rotation=20);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regresión logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Con todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion cruzada\n",
    "reglog = LogisticRegression(max_iter = 500)\n",
    "vc = cross_val_score(reglog, scaler.transform(X_train), y_train, cv = 5, scoring = \"accuracy\")\n",
    "accuracy = vc.mean()\n",
    "print(\"Accuracy para Regresión Logística con validación cruzada: {:1.4f} \".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reglog = LogisticRegression(max_iter=500)\n",
    "reglog.fit(scaler.transform(X_train),y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reglog.predict(scaler.transform(X_test))\n",
    "print(\"El accuracy del test es: {:1.4f}\".format( accuracy_score(y_test, y_pred) ))\n",
    "print(\"La sensitividad(recall) del test es: {:1.4f}\".format( recall_score(y_test, y_pred) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CM(y_test, y_pred,norm='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(reglog, X_test, y_test, scaler, model_name='Regresión logítica con todas las variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Regresión logística con variables seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regLog2, X_test2, y_test2, y_pred2, scaler2 = reg_log(X_fselec, y_down_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CM(y_test2, y_pred2,norm='true')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(regLog2, X_test2, y_test2, scaler2, model_name='Regresión logística con selección de variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusión:\n",
    "Tanto el accuracy como el ROC_AUC score son mejores con todas las variables comparado a cuando se seleccionan variables. Por lo tanto, conservar todas las variables es lo mejor para la regresión logística."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Bosque aleatorio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# con variables seleccionadas para que no tarde demasiado\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fselec, y_down_MA, test_size = 0.3, random_state = 42, stratify = y_down_MA)\n",
    "#scaler = preprocessing.StandardScaler().fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validacion cruzada\n",
    "forest = RandomForestClassifier(random_state=42)\n",
    "vc = cross_val_score(forest, X_train, y_train, cv = 5, scoring = \"accuracy\")\n",
    "accuracy = vc.mean()\n",
    "print(\"Accuracy promedio para Bosque Aleatorio con validación cruzada: {:1.4f} \".format(accuracy) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Con todas las variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest, X_test, y_test, y_pred_forest, scaler = random_forest(X_down_MA, y_down_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CM(y_test, y_pred_forest,norm=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(forest, X_test, y_test, scaler, model_name='Bosque aleatorio con todas las variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Con variables seleccionadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest2, X_test2, y_test2, y_pred_forest2, scaler2 = random_forest(X_fselec.iloc[:,1:], y_down_MA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CM(y_test2, y_pred_forest2,norm=\"true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(forest2, X_test2, y_test2, scaler2, model_name='Bosque aleatorio con selección de variables')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elección de hiperparametros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc = RandomForestClassifier(random_state=42)\n",
    "parametros_a_probar = {\"n_estimators\": [100,200], \n",
    "          \"max_features\" : [\"sqrt\", \"log2\", 0.2, 0.5],\n",
    "          \"min_samples_leaf\": [1,20, 0.01, 0.05],\n",
    "          \"class_weight\": [{0:1,1:1}, {0:1,1:1.5}, {0:1,1:2}],  #Cost of missclasification\n",
    "         }\n",
    "metricas = ['accuracy','recall']\n",
    "clf_grid = GridSearchCV(rfc, parametros_a_probar, scoring=metricas, cv=5, refit='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fselec, y_down_MA, \n",
    "                                                    test_size = 0.3, random_state = 42, stratify = y_down_MA)\n",
    "scaler = preprocessing.StandardScaler().fit(X_train)\n",
    "\n",
    "clf_grid.fit(scaler.transform(X_train), y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_arb = clf_grid.predict(scaler.transform(X_test))\n",
    "print(\"Accuracy del test: {:1.4f}\".format( accuracy_score(y_test, y_pred_arb) ))\n",
    "print(\"La sensitividad(recall) del test es: {:1.4f}\".format( recall_score(y_test, y_pred_arb) ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_CM(y_test, y_pred_arb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_ROC(clf_grid, X_test, y_test, scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "- El **bosque aleatorio clasifica mucho mejor que la regresión logística. Los resultados parecen correctos, teniendo en cuenta que se hizo una validación cruzada 5-fold y que el accuracy para el bosque aleatorio es en promedio igual a 0.98 mientras que con la regresión logística, el accuracy promedio es igual a 0.7 **(validar con grafica)**\n",
    "- La diferencia de la precisión de los modelos entre con y sin selección de variables es mínima con Random Forest. Por lo tanto para que los modelos no se tarden ejecutando demasiado, **es mejor quedarse con las variables filtradas** **(poner listado)**\n",
    "- La **elección de hiperparámetros queda pendiente** porque tarda bastante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
